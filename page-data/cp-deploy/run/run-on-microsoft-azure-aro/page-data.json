{"componentChunkName":"component---src-pages-cp-deploy-run-run-on-microsoft-azure-aro-mdx","path":"/cp-deploy/run/run-on-microsoft-azure-aro/","result":{"pageContext":{"frontmatter":{"title":"Run on Microsoft Azure - ARO","tabs":["Run on IBM Cloud","Run on vSphere","Run on AWS","Run on Microsoft Azure - ARO","Run on existing OpenShift"]},"relativePagePath":"/cp-deploy/run/run-on-microsoft-azure-aro.mdx","titleType":"page","MdxNode":{"id":"21fdf205-5b95-585a-8218-63614868d7e0","children":[],"parent":"4193a8bc-6fbe-5e5e-b549-1bd28157b571","internal":{"content":"---\ntitle: Run on Microsoft Azure - ARO\ntabs:\n  [\n    \"Run on IBM Cloud\",\n    \"Run on vSphere\",\n    \"Run on AWS\",\n    \"Run on Microsoft Azure - ARO\",\n    \"Run on existing OpenShift\",\n  ]\n---\n\n# Running the Cloud Pak Deployer on Microsoft Azure - ARO\n\n## Topology\n\nA typical setup of the ARO cluster is pictured below:\n![ARO configuration](azure-aro.png)\n\nThe ARO cluster is deployed by using the Terraform in combination with the Azure Resource Manager (ARM) template.\n\nWhen deploying ARO, you can partially configure the domain name by setting the `openshift.subdomain_name` attribute. The resulting domain name is managed by Azure, and it must be unique across all ARO instances deployed in Azure. Both the API and Ingress urls are set to be public in the template, so they can be resolved by external clients.\n\n## Acquire an Red Hat OpenShift pull secret\n\nTo install OpenShift you need an OpenShift pull secret which holds your entitlement.\n\n- Navigate and login to [Red Hat OpenShift cluster manager portal](https://cloud.redhat.com/openshift/install/azure/aro-provisioned)\n\n- Click on `Download pull secret` button, and save the pull secret into the `/tmp/ocp_pullsecret.json` file.\n\n## Acquire an IBM Cloud Pak Entitlement Key\n\nIf you want to pull the Cloud Pak images from the entitled registry (i.e. an online install), or if you want to mirror the images to your private registry, you need to download the entitlement key. You can skip this step if you're installing from a private registry and all Cloud Pak images have already been downloaded to the private registry.\n\n- Navigate to https://myibm.ibm.com/products-services/containerlibrary and login with your IBMId credentials\n- Select **Get Entitlement Key** and create a new key (or copy your existing key)\n- Copy the key value\n\n<InlineNotification kind=\"warning\">\n  As stated for the API key, you can choose to download the entitlement key to a\n  file. However, when we reference the entitlement key, we mean the 80+\n  character string that is displayed, not the file.\n</InlineNotification>\n\n## Verify your permissions in Microsoft Azure\n\n- Check [Azure resource quota](https://docs.microsoft.com/en-us/azure/openshift/tutorial-create-cluster#before-you-begin) of the subscription - Azure Red Hat OpenShift requires a minimum of 40 cores to create and run an OpenShift cluster.\n- The ARO cluster is provisioned by using ARM template which expects Service Principal to be created and used. Ideally, one has to have `Contributor` permissions on the subscription (Azure resources) and `Application administrator` role assigned in the Azure Active Directory. See details [here](https://docs.microsoft.com/en-us/azure/openshift/tutorial-create-cluster#verify-your-permissions).\n\n## Login to the Microsoft Azure\n\nYou are required to create a Service Principal and get Azure Red Hat OpenShift Resource Provider objectId before starting the deployment. The future steps expect that you are logged in to the Microsoft Azure by using CLI. You can either:\n\n- [Install Azure CLI tool](https://learn.hashicorp.com/tutorials/terraform/install-cli?in=terraform/azure-get-started#install-terraform), and run the commands in your operationg system, or\n- use the Azure CLI tool which is already installed in the deployer image. You need to run the container with the overridden entrypoint, and thus get the interactive access to the tools inside ([`docker` | `podman`]), i.e: `docker run -it --name cpd-cli --entrypoint /bin/bash cloud-pak-deployer:latest`\n\nLogin to the Microsoft Azure:\n\n- Azure Cloud CLI: `az login`\n- If your tenant requires Multi-Factor Authentication (MFA), use: `az login --tenant <TENANT_ID>`\n- If you have multiple Azure subscriptions, specify the relevant subscription ID: `az account set --subscription <SUBSCRIPTION_ID>`\n\n## Register Resource Providers\n\nMake sure the following Resource Providers are registered for your subscription by running:\n\n```bash\naz provider register -n Microsoft.RedHatOpenShift --wait\naz provider register -n Microsoft.Compute --wait\naz provider register -n Microsoft.Storage --wait\naz provider register -n Microsoft.Authorization --wait\n```\n\n## Create a Service Principal\n\n```bash\n# Specify a name for your service principal, e.g. cpd-sp\nexport SPNAME=cpd-sp\n\n# Create your service principal\naz ad sp create-for-rbac --name $SPNAME\n# {\n#   \"appId\": \"694bxxx\",          ---> service_principal_id parameter\n#   \"displayName\": \"$SPNAME\",\n#   \"name\": \"694xxx\",\n#   \"password\": \"CXxxx\",         ---> service_principal_secret parameter\n#   \"tenant\": \"bb0xxx\"\n# }\n\n# Get objectId of your service principal\naz ad sp list --filter \"displayname eq '$SPNAME'\" --query \"[?appDisplayName=='$SPNAME'].{name: appDisplayName, objectId: objectId}\"\n# [\n#   {\n#     \"name\": \"$SPNAME\",\n#     \"objectId\": \"70bdxxx\"      ---> service_principal_object_id parameter\n#   }\n# ]\n```\n\nYou may want to create the service principal with the `Contributor` role by adding `--role=\"Contributor\"` (the first command above). Anyhow, in the ARM template, the Contributor role is assigned to the given service principal (Virtual Network scope).\n\n<InlineNotification kind=\"info\">\n  Pay attention to the \"service_principal_id\", \"service_principal_secret\", and\n  \"service_principal_object_id\" output parameter notes. They will be used later.\n</InlineNotification>\n\n## Get Azure Red Hat OpenShift Resource Provider objectId\n\nThe ARM template also needs to grant the ARO 4 Resource Provider service principal permissions in order to provision and manage clusters. To obtain the ARO 4 RP service principal object id execute the following command:\n\n```bash\naz ad sp list --filter \"displayname eq 'Azure Red Hat OpenShift RP'\" --query \"[?appDisplayName=='Azure Red Hat OpenShift RP'].{name: appDisplayName, objectId: objectId}\"\n# [\n#   {\n#     \"name\": \"Azure Red Hat OpenShift RP\",\n#     \"objectId\": \"28exxx\"       ---> aro_rp_object_id parameter\n#   }\n# ]\n```\n\n<InlineNotification kind=\"info\">\n  Pay attention to the \"aro_rp_object_id\" output parameter note. This will be\n  used later.\n</InlineNotification>\n\n## Prepare for running\n\n### Set environment variables\n\n```\nexport ARO_TENANT_ID=your_tenant_id\nexport ARO_SUBSCRIPTION_ID=your_subscription_id\nexport ARO_SP_ID=service_principal_id_created_above\nexport ARO_SP_SECRET=service_principal_secret_created_above\nexport ARO_SP_OBJECT_ID=service_principal_object_id_created_above\nexport ARO_RP_OBJECT_ID=aro_rp_object_id_obtained_above\n\nexport CP_ENTITLEMENT_KEY=your_cp_entitlement_key\n\nexport STATUS_DIR=/data/status/sample\nexport CONFIG_DIR=/data/config/sample\n```\n\n- `ARO_TENANT_ID`: Azure Active Directory tenant id.\n- `ARO_SUBSCRIPTION_ID`: Subscription id (agreement) with Microsoft to use one or more Microsoft cloud platforms or services. An organization can have multiple subscriptions that use the same Azure AD tenant.\n- `ARO_SP_ID`: Service Principal id (appId) which is used to login to Microsoft Azure by the terraform process. At the same time, the ARM template uses the same Service Principal to deploy the cluster.\n- `ARO_SP_SECRET`: Secret password of the Service Principal\n- `ARO_SP_OBJECT_ID`: Object id of the Service Principal\n- `ARO_RP_OBJECT_ID`: Object id of the Azure Red Hat OpenShift Resource Provider\n- `CP_ENTITLEMENT_KEY`: This is the entitlement key you acquired as per the instructions above, this is a 80+ character string\n- `STATUS_DIR`: The directory where the Cloud Pak Deployer keeps all status information and logs files. **Please note** that if you have chosen to use a File Vault, the properties file is keps under the `vault` directory within the status directory\n- `CONFIG_DIR`: Directory that holds the configuration, it must have `config`, `defaults` and `inventory` subdirectories\n\n<InlineNotification>\n  Cloud Pak Deployer uses the status directory to logs its activities and also\n  to keep track of its running state. For a given environment you're\n  provisioning or destroying, you should always specify the same status\n  directory to avoid contention between different deploy runs. You can run the\n  Cloud Pak Deployer in parallel for different environments (different\n  configuration directories).\n</InlineNotification>\n\n### Create the secrets needed for ARO\n\nYou need to store all `ARO_` environments variables together with the OpenShift pull secret in the vault so that the deployer has access to them.\n\n```\n./cp-deploy.sh vault set \\\n    --vault-secret aro-tenant-id \\\n    --vault-secret-value $ARO_TENANT_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-subscription-id \\\n    --vault-secret-value $ARO_SUBSCRIPTION_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-sp-id \\\n    --vault-secret-value $ARO_SP_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-sp-secret \\\n    --vault-secret-value $ARO_SP_SECRET\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-sp-object-id \\\n    --vault-secret-value $ARO_SP_OBJECT_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-rp-object-id \\\n    --vault-secret-value $ARO_RP_OBJECT_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret ocp-pullsecret \\\n    --vault-secret-file /tmp/ocp_pullsecret.json\n```\n\n## Run the Cloud Pak Deployer\n\nTo run the container using a local configuration input directory and a data directory where temporary and state is kept, use the example below. If you don't specify the status directory, the deployer will automatically create a temporary directory. Please note that the status directory will also hold secrets if you have configured a flat file vault. If you lose the directory, you will not be able to make changes to the configuration and adjust the deployment. It is best to specify a permanent directory that you can reuse later. If you specify an existing directory the current user **must** be the owner of the directory. Failing to do so may cause the container to fail with insufficient permissions.\n\n```\n./cp-deploy.sh env apply -e env_id=pluto-01 -e azure_location=westeurope [--accept-all-licenses]\n```\n\nFor more information about the extra (dynamic) variables, see [advanced configuration](/advanced/advanced-configuration).\n\nThe `--accept-all-licenses` flag is optional and confirms that you accept all licenses of the installed cartridges and instances. Licenses must be either accepted in the configuration files or at the command line.\n\nWhen running the command, the container will start as a daemon and the command will tail-follow the logs. You can press Ctrl-C at any time to interrupt the logging but the container will continue to run in the background.\n\nYou can return to view the logs as follows:\n\n```\n./cp-deploy.sh env logs\n```\n\nDeploying the infrastructure, preparing OpenShift and installing the Cloud Pak will take a long time, typically between 1-5 hours, dependent on which Cloud Pak cartridges you configured. For estimated duration of the steps, refer to [Timings](/cpd-design/timings).\n\nIf you need to interrupt the automation, use CTRL-C to stop the logging output and then use:\n\n```\n./cp-deploy.sh env kill\n```\n\n## Finishing up\n\n<InlineNotification kind=\"warning\">\n  WIP - TODO: update this block once finished\n</InlineNotification>\n\nOnce the process has finished, it will output the URLs by which you can access the deployed Cloud Pak. You can also find this information under the `cloud-paks` directory in the status directory you specified. The `admin` password can be retrieved from the vault as follows:\n\nList the secrets in the vault:\n\n```\n./cp-deploy.sh vault list\n```\n\nThis will show something similar to the following:\n\n```output\nSecret list for group sample:\n- ibm_cp_entitlement_key\n- sample-provision-ssh-key\n- sample-provision-ssh-pub-key\n- sample-terraform-tfstate\n- cp4d_admin_zen_sample_sample\n```\n\nYou can then retrieve the Cloud Pak for Data admin password like this:\n\n```\n./cp-deploy.sh vault get --vault-secret cp4d_admin_zen_sample_sample\n```\n\n```output\nPLAY [Secrets] *****************************************************************\nincluded: /automation_script/automation-roles/99-generic/vault/vault-get-secret/tasks/get-secret-file.yml for localhost\ncp4d_admin_zen_sample_sample: gelGKrcgaLatBsnAdMEbmLwGr\n```\n","type":"Mdx","contentDigest":"b357b5f84e6b1b538f7577c91eea7639","owner":"gatsby-plugin-mdx","counter":205},"frontmatter":{"title":"Run on Microsoft Azure - ARO","tabs":["Run on IBM Cloud","Run on vSphere","Run on AWS","Run on Microsoft Azure - ARO","Run on existing OpenShift"]},"exports":{},"rawBody":"---\ntitle: Run on Microsoft Azure - ARO\ntabs:\n  [\n    \"Run on IBM Cloud\",\n    \"Run on vSphere\",\n    \"Run on AWS\",\n    \"Run on Microsoft Azure - ARO\",\n    \"Run on existing OpenShift\",\n  ]\n---\n\n# Running the Cloud Pak Deployer on Microsoft Azure - ARO\n\n## Topology\n\nA typical setup of the ARO cluster is pictured below:\n![ARO configuration](azure-aro.png)\n\nThe ARO cluster is deployed by using the Terraform in combination with the Azure Resource Manager (ARM) template.\n\nWhen deploying ARO, you can partially configure the domain name by setting the `openshift.subdomain_name` attribute. The resulting domain name is managed by Azure, and it must be unique across all ARO instances deployed in Azure. Both the API and Ingress urls are set to be public in the template, so they can be resolved by external clients.\n\n## Acquire an Red Hat OpenShift pull secret\n\nTo install OpenShift you need an OpenShift pull secret which holds your entitlement.\n\n- Navigate and login to [Red Hat OpenShift cluster manager portal](https://cloud.redhat.com/openshift/install/azure/aro-provisioned)\n\n- Click on `Download pull secret` button, and save the pull secret into the `/tmp/ocp_pullsecret.json` file.\n\n## Acquire an IBM Cloud Pak Entitlement Key\n\nIf you want to pull the Cloud Pak images from the entitled registry (i.e. an online install), or if you want to mirror the images to your private registry, you need to download the entitlement key. You can skip this step if you're installing from a private registry and all Cloud Pak images have already been downloaded to the private registry.\n\n- Navigate to https://myibm.ibm.com/products-services/containerlibrary and login with your IBMId credentials\n- Select **Get Entitlement Key** and create a new key (or copy your existing key)\n- Copy the key value\n\n<InlineNotification kind=\"warning\">\n  As stated for the API key, you can choose to download the entitlement key to a\n  file. However, when we reference the entitlement key, we mean the 80+\n  character string that is displayed, not the file.\n</InlineNotification>\n\n## Verify your permissions in Microsoft Azure\n\n- Check [Azure resource quota](https://docs.microsoft.com/en-us/azure/openshift/tutorial-create-cluster#before-you-begin) of the subscription - Azure Red Hat OpenShift requires a minimum of 40 cores to create and run an OpenShift cluster.\n- The ARO cluster is provisioned by using ARM template which expects Service Principal to be created and used. Ideally, one has to have `Contributor` permissions on the subscription (Azure resources) and `Application administrator` role assigned in the Azure Active Directory. See details [here](https://docs.microsoft.com/en-us/azure/openshift/tutorial-create-cluster#verify-your-permissions).\n\n## Login to the Microsoft Azure\n\nYou are required to create a Service Principal and get Azure Red Hat OpenShift Resource Provider objectId before starting the deployment. The future steps expect that you are logged in to the Microsoft Azure by using CLI. You can either:\n\n- [Install Azure CLI tool](https://learn.hashicorp.com/tutorials/terraform/install-cli?in=terraform/azure-get-started#install-terraform), and run the commands in your operationg system, or\n- use the Azure CLI tool which is already installed in the deployer image. You need to run the container with the overridden entrypoint, and thus get the interactive access to the tools inside ([`docker` | `podman`]), i.e: `docker run -it --name cpd-cli --entrypoint /bin/bash cloud-pak-deployer:latest`\n\nLogin to the Microsoft Azure:\n\n- Azure Cloud CLI: `az login`\n- If your tenant requires Multi-Factor Authentication (MFA), use: `az login --tenant <TENANT_ID>`\n- If you have multiple Azure subscriptions, specify the relevant subscription ID: `az account set --subscription <SUBSCRIPTION_ID>`\n\n## Register Resource Providers\n\nMake sure the following Resource Providers are registered for your subscription by running:\n\n```bash\naz provider register -n Microsoft.RedHatOpenShift --wait\naz provider register -n Microsoft.Compute --wait\naz provider register -n Microsoft.Storage --wait\naz provider register -n Microsoft.Authorization --wait\n```\n\n## Create a Service Principal\n\n```bash\n# Specify a name for your service principal, e.g. cpd-sp\nexport SPNAME=cpd-sp\n\n# Create your service principal\naz ad sp create-for-rbac --name $SPNAME\n# {\n#   \"appId\": \"694bxxx\",          ---> service_principal_id parameter\n#   \"displayName\": \"$SPNAME\",\n#   \"name\": \"694xxx\",\n#   \"password\": \"CXxxx\",         ---> service_principal_secret parameter\n#   \"tenant\": \"bb0xxx\"\n# }\n\n# Get objectId of your service principal\naz ad sp list --filter \"displayname eq '$SPNAME'\" --query \"[?appDisplayName=='$SPNAME'].{name: appDisplayName, objectId: objectId}\"\n# [\n#   {\n#     \"name\": \"$SPNAME\",\n#     \"objectId\": \"70bdxxx\"      ---> service_principal_object_id parameter\n#   }\n# ]\n```\n\nYou may want to create the service principal with the `Contributor` role by adding `--role=\"Contributor\"` (the first command above). Anyhow, in the ARM template, the Contributor role is assigned to the given service principal (Virtual Network scope).\n\n<InlineNotification kind=\"info\">\n  Pay attention to the \"service_principal_id\", \"service_principal_secret\", and\n  \"service_principal_object_id\" output parameter notes. They will be used later.\n</InlineNotification>\n\n## Get Azure Red Hat OpenShift Resource Provider objectId\n\nThe ARM template also needs to grant the ARO 4 Resource Provider service principal permissions in order to provision and manage clusters. To obtain the ARO 4 RP service principal object id execute the following command:\n\n```bash\naz ad sp list --filter \"displayname eq 'Azure Red Hat OpenShift RP'\" --query \"[?appDisplayName=='Azure Red Hat OpenShift RP'].{name: appDisplayName, objectId: objectId}\"\n# [\n#   {\n#     \"name\": \"Azure Red Hat OpenShift RP\",\n#     \"objectId\": \"28exxx\"       ---> aro_rp_object_id parameter\n#   }\n# ]\n```\n\n<InlineNotification kind=\"info\">\n  Pay attention to the \"aro_rp_object_id\" output parameter note. This will be\n  used later.\n</InlineNotification>\n\n## Prepare for running\n\n### Set environment variables\n\n```\nexport ARO_TENANT_ID=your_tenant_id\nexport ARO_SUBSCRIPTION_ID=your_subscription_id\nexport ARO_SP_ID=service_principal_id_created_above\nexport ARO_SP_SECRET=service_principal_secret_created_above\nexport ARO_SP_OBJECT_ID=service_principal_object_id_created_above\nexport ARO_RP_OBJECT_ID=aro_rp_object_id_obtained_above\n\nexport CP_ENTITLEMENT_KEY=your_cp_entitlement_key\n\nexport STATUS_DIR=/data/status/sample\nexport CONFIG_DIR=/data/config/sample\n```\n\n- `ARO_TENANT_ID`: Azure Active Directory tenant id.\n- `ARO_SUBSCRIPTION_ID`: Subscription id (agreement) with Microsoft to use one or more Microsoft cloud platforms or services. An organization can have multiple subscriptions that use the same Azure AD tenant.\n- `ARO_SP_ID`: Service Principal id (appId) which is used to login to Microsoft Azure by the terraform process. At the same time, the ARM template uses the same Service Principal to deploy the cluster.\n- `ARO_SP_SECRET`: Secret password of the Service Principal\n- `ARO_SP_OBJECT_ID`: Object id of the Service Principal\n- `ARO_RP_OBJECT_ID`: Object id of the Azure Red Hat OpenShift Resource Provider\n- `CP_ENTITLEMENT_KEY`: This is the entitlement key you acquired as per the instructions above, this is a 80+ character string\n- `STATUS_DIR`: The directory where the Cloud Pak Deployer keeps all status information and logs files. **Please note** that if you have chosen to use a File Vault, the properties file is keps under the `vault` directory within the status directory\n- `CONFIG_DIR`: Directory that holds the configuration, it must have `config`, `defaults` and `inventory` subdirectories\n\n<InlineNotification>\n  Cloud Pak Deployer uses the status directory to logs its activities and also\n  to keep track of its running state. For a given environment you're\n  provisioning or destroying, you should always specify the same status\n  directory to avoid contention between different deploy runs. You can run the\n  Cloud Pak Deployer in parallel for different environments (different\n  configuration directories).\n</InlineNotification>\n\n### Create the secrets needed for ARO\n\nYou need to store all `ARO_` environments variables together with the OpenShift pull secret in the vault so that the deployer has access to them.\n\n```\n./cp-deploy.sh vault set \\\n    --vault-secret aro-tenant-id \\\n    --vault-secret-value $ARO_TENANT_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-subscription-id \\\n    --vault-secret-value $ARO_SUBSCRIPTION_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-sp-id \\\n    --vault-secret-value $ARO_SP_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-sp-secret \\\n    --vault-secret-value $ARO_SP_SECRET\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-sp-object-id \\\n    --vault-secret-value $ARO_SP_OBJECT_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret aro-rp-object-id \\\n    --vault-secret-value $ARO_RP_OBJECT_ID\n\n./cp-deploy.sh vault set \\\n    --vault-secret ocp-pullsecret \\\n    --vault-secret-file /tmp/ocp_pullsecret.json\n```\n\n## Run the Cloud Pak Deployer\n\nTo run the container using a local configuration input directory and a data directory where temporary and state is kept, use the example below. If you don't specify the status directory, the deployer will automatically create a temporary directory. Please note that the status directory will also hold secrets if you have configured a flat file vault. If you lose the directory, you will not be able to make changes to the configuration and adjust the deployment. It is best to specify a permanent directory that you can reuse later. If you specify an existing directory the current user **must** be the owner of the directory. Failing to do so may cause the container to fail with insufficient permissions.\n\n```\n./cp-deploy.sh env apply -e env_id=pluto-01 -e azure_location=westeurope [--accept-all-licenses]\n```\n\nFor more information about the extra (dynamic) variables, see [advanced configuration](/advanced/advanced-configuration).\n\nThe `--accept-all-licenses` flag is optional and confirms that you accept all licenses of the installed cartridges and instances. Licenses must be either accepted in the configuration files or at the command line.\n\nWhen running the command, the container will start as a daemon and the command will tail-follow the logs. You can press Ctrl-C at any time to interrupt the logging but the container will continue to run in the background.\n\nYou can return to view the logs as follows:\n\n```\n./cp-deploy.sh env logs\n```\n\nDeploying the infrastructure, preparing OpenShift and installing the Cloud Pak will take a long time, typically between 1-5 hours, dependent on which Cloud Pak cartridges you configured. For estimated duration of the steps, refer to [Timings](/cpd-design/timings).\n\nIf you need to interrupt the automation, use CTRL-C to stop the logging output and then use:\n\n```\n./cp-deploy.sh env kill\n```\n\n## Finishing up\n\n<InlineNotification kind=\"warning\">\n  WIP - TODO: update this block once finished\n</InlineNotification>\n\nOnce the process has finished, it will output the URLs by which you can access the deployed Cloud Pak. You can also find this information under the `cloud-paks` directory in the status directory you specified. The `admin` password can be retrieved from the vault as follows:\n\nList the secrets in the vault:\n\n```\n./cp-deploy.sh vault list\n```\n\nThis will show something similar to the following:\n\n```output\nSecret list for group sample:\n- ibm_cp_entitlement_key\n- sample-provision-ssh-key\n- sample-provision-ssh-pub-key\n- sample-terraform-tfstate\n- cp4d_admin_zen_sample_sample\n```\n\nYou can then retrieve the Cloud Pak for Data admin password like this:\n\n```\n./cp-deploy.sh vault get --vault-secret cp4d_admin_zen_sample_sample\n```\n\n```output\nPLAY [Secrets] *****************************************************************\nincluded: /automation_script/automation-roles/99-generic/vault/vault-get-secret/tasks/get-secret-file.yml for localhost\ncp4d_admin_zen_sample_sample: gelGKrcgaLatBsnAdMEbmLwGr\n```\n","fileAbsolutePath":"/home/runner/work/cloud-pak-deployer/cloud-pak-deployer/doc/src/pages/cp-deploy/run/run-on-microsoft-azure-aro.mdx"}}},"staticQueryHashes":["1364590287","137577622","137577622","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}